\documentclass[11pt]{article}
\usepackage{tcolorbox}
\tcbuselibrary{breakable}
\tcbuselibrary{theorems}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[margin=0.8in]{geometry}
\usepackage{xcolor}              
\usepackage[colorlinks = true]{hyperref}

%Theorem, Lemma, Definition etc. Boxes
\newtcbtheorem[number within = section]{theorem}{Theorem}{colback = blue!5, colframe = blue!60!black, fonttitle=\bfseries}{th}

\newtcbtheorem[number within = section]{lemma}{Lemma}{colback = blue!5, colframe = blue!60!black, fonttitle=\bfseries}{lm}

\newtcbtheorem[number within = section]{definition}{Definition}{colback = red!5, colframe = red!75!black, fonttitle=\bfseries}{df}

\newtcbtheorem{example}{Example}{colback = green!5,
	colframe = green!35!black,fonttitle = \bfseries, breakable = true}{eg}

\newtcolorbox{summary}{title = Section Summary:, colback = yellow!10, 
	colframe = yellow!75!red!90, fonttitle = \bfseries}

\newtcolorbox{exercise}{title = Exercises, colback = green!5,
	colframe = green!35!black,fonttitle = \bfseries}

%Header
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\lhead{UNSW Business School}
\rhead{ACTL3182 Formula Sheet}
\cfoot{Page \thepage}  %PERHAPS Add UNSW COPYRIGHT FOOTER
\setlength{\headheight}{17pt} 

\title{\textbf{ACTL3182 Lagrange Multipliers Revision}}
\author{Andrew Wu}
\date{September 2020}

%Section formatting
\usepackage{titlesec}
\titleformat{\section}{\Large\sffamily\bfseries\color{black}}{\thesection}{0.5em}{}[]
\titleformat{\subsection}{\large\sffamily\bfseries}{\thesubsection}{0.5em}{}
\titleformat{\subsubsection}{\normalsize\sffamily\bfseries}{\thesubsubsection}{0.5em}{}

%Math Shortcuts
\newcommand{\R}{\mathbb{R}}
\newcommand{\vx}{\bm{x}}

\begin{document}
	\maketitle
	\noindent This sheet provides a brief revision and some basic examples on Lagrange multipliers, a common method in constrained optimisation. The examples and exercises (Appendix) are optional though helpful for a better understanding of the technique.\\ In ACTL3182, the questions on Lagrange multipliers will not be like the examples in this sheet. If any derivation is required, it will most likely be very similar to the lecture slides.
	
	\section{Lagrange Multipliers}
	%\subsection{The Theorem}
	We begin simple with the one-constraint case that you learnt in MATH1251.
	\begin{definition}{Gradient}{}
		The gradient (or derivative) of a function \( f:\R^{n}\to\R \), is the vector of partial derivatives:

		\[	\nabla f =		\left[\frac{\partial f}{\partial x_1}  , \frac{\partial f}{\partial x_2} , ... , \frac{\partial f}{\partial x_n}\right]^{\top}				
			\]
		\tcblower
		\begin{itemize}
			\item \( \nabla f \) is equivalent to the vector derivative \( \frac{\partial f}{\partial \bm{x}} \) when \( \vx\in\R^n \) i.e. when \( \vx \) is a vector of the same dimensions as the domain.
			\item \( \nabla f \) is the direction of the tangent plane just as \( f'(x) \) is the slope of the tangent in one dimension.
		\end{itemize}
	\end{definition}
	\bigskip
	\noindent 
	\begin{theorem}{Lagrange Multipliers (one constraint)}{}
		Let \( f:\R^n \to\R \) denote the function to be optimised, subject to the constraint 
		\[	g(\vx) = C, \]
		where \( \vx\in\R^n \)	and \( C\in\R \) is a constant. If \( \nabla g \neq 0 \), then \( f \) achieves its maxima/minima at the points where 
		\[	\nabla f = \lambda g.\]
		\tcblower
		\begin{itemize}
			\item Essentially, the gradients of \( f,g \) must be parallel for \( f \) to be maximised or minimised.
			\item The constant \( \lambda \) is called a \textbf{Lagrange Multiplier}
		\end{itemize} 
	\end{theorem}
\smallskip
	\noindent \textbf{Note:} \( \nabla f = \lambda\nabla g \) is a \textbf{necessary but not a sufficient} condition for optima. That is, the equation can still hold at some point that is not actually a maximum or minimum. Therefore it is important to check the value of \( f \) at each point where \( \nabla f = \lambda\nabla g \), or compute the Hessian matrix (this is essentially the second derivative test in higher dimensions). 
	\begin{example}{One constraint}{}
		%\begin{enumerate}
			%\item 
			Find the points where the function \( f:\R^2\to\R \), \( f(x, y) = xy \), is maximised on the ellipse
			\[	\frac{x^2}{2} + \frac{y^2}{3} = 1
			\]
			%\item Sketch the Ellipse and contour lines
		%\end{enumerate}
		\end{example}
	\noindent \textbf{Solution:} Let \( g \) be the function given by
	\[	g(x, y) = \frac{x^2}{2} + \frac{y^2}{3}
	\]
	Hence, we need to maximise \( f \) with respect to the constraint \( g(x,y) = 1 \).
	By the method of Lagrange multipliers, the maxima of \( f \) occur when 
	\begin{align*}
		     &\nabla f = \lambda g, \quad\text{for some }\lambda\in\R\\
		\iff & \left[y, x\right]^{\top} = \lambda \left[x, \frac{2y}{3}\right]^{\top} \\
		\iff & y = \lambda x\quad (1), \quad\text{and}\quad x = \lambda\cdot\frac{2y}{3} \quad (2)
	\end{align*}
	Dividing \( (1) \) by \( (2) \), we obtain
	\begin{align*}
		 	 & \frac{y}{x} = \frac{3x}{2y} \\
		\iff & y^2 = \frac{3}{2}x^2\qquad (3).
	\end{align*}
	Substituting (3) into the constraint \( g(x,y) = 1 \), 
	\begin{align*}
			 & \frac{x^2}{2} + \frac{\frac{3}{2} x^2}{3} = 1 \\
		\iff & x = \pm 1
	\end{align*}
	Resubstituting into \( (3) \), we obtain \( y = \pm\sqrt{3/2} \). Clearly \( f \) is maximised when \( xy >0 \), so \( f \) achieves its maximum at the points \( (1, \sqrt{3/2}) \) and \((-1, -\sqrt{3/2})  \). Notice that we did not need to find the value of \( \lambda \) in this example, although sometimes it is easier to do so.\\\\
	\noindent Now, we state the two-constraint theorem. Solving the two-constraint case by hand is complicated so the example has been moved to the appendix.\\
	\begin{theorem}{Lagrange Multipliers (two constraints)}{}
			Let \( f:\R^n \to\R \) denote the function to be optimised, subject to the constraints 
		\begin{align*}
			& g_{1}(\vx) = C_1 \\
			& g_{2}(\vx) = C_2 
		\end{align*}
		where \( \vx\in\R^n \) and \( C_1, C_2 \) are real constants. If \( \nabla g_1, \nabla g_2 \neq0 \), then \( f \) achieves its maxima/minima at the points where
		\begin{align*}
			\nabla f = \lambda \nabla g_1 + \gamma \nabla g_2,
		\end{align*}
		where \( \lambda, \gamma \in\R\) are the Lagrange multipliers.
	\end{theorem}
	\newpage
	\section{The Lagrangian}
	When we have more than one constraint, it is useful to repackage the constraints and the optimisation into a single function, which we can then optimise. This function is called the \textbf{Lagrangian}. \\
	\begin{theorem}{Lagrange Multipliers (two constraints using the Lagrangian)}{}
			Let \( f:\R^n \to\R \) denote the function to be optimised, subject to the constraints 
		\begin{align*}
		& g_{1}(\vx) = C_1 \\
		& g_{2}(\vx) = C_2 
		\end{align*}
		where \( \vx\in\R^n \) and \( C_1, C_2 \) are real constants. The \textbf{Lagrangian} for the problem above is the function \( \mathcal{L} \), where
		\[	\mathcal{L}(\vx, \lambda, \gamma) = f(\vx) + \lambda (C_{1} - g_{1}(\vx)) + \gamma( C_{2} - g_{2}(\vx))
		\]
		The function \( f \) achieves its maxima/minima when \(\nabla \mathcal{L} = 0 \), or equivalently,
		\begin{align*}
			 \frac{\partial \mathcal{L}}{\partial \bm{x}} = \bm{0}, \qquad
			 \frac{\partial \mathcal{L}}{\partial \lambda} = 0 ,\qquad \text{and}\quad
			 \frac{\partial \mathcal{L}}{\partial \gamma} = 0.
		\end{align*}
		where \( \bm{0}\in\R^n \) is the zero vector.
	\end{theorem}
 	\noindent The three conditions on the Lagrangian are equivalent to \textbf{Theorem 1.2}. The first condition equates the gradient of \( f \) to a linear combination of the gradients of \( g_1,g_2 \):
 	\begin{align*}
 		     & \frac{\partial \mathcal{L}}{\partial \bm{x}} = \bm{0} \\
 		\iff & 	\nabla f -\lambda \nabla g_1 - \gamma \nabla g_2 = \bm{0} \\
 		\iff & \nabla f = \lambda \nabla g_1 + \gamma \nabla g_2
 		\end{align*}
	The second and third conditions simply capture the constraints in the original problem:
	\begin{align*}
		&\frac{\partial \mathcal{L}}{\partial \lambda} = C_1 - g_1(\vx) = 0\iff g_1(\vx) = C_1 \\
		&\frac{\partial \mathcal{L}}{\partial \gamma} = C_1 - g_2(\vx) = 0\iff g_2(\vx) = C_1.
	\end{align*}
	\textbf{Why use the Lagrangian?} When solving problems by hand, it is not always useful. However, this form is signficantly better for implementing Lagrange multipliers using a computer.\\ This is because the computer can now treat the problem as one about finding where the gradient \( \nabla \mathcal{L} = 0\),
	for which there exist nice optimisation techniques. \\Conversely, if we were to use the form Theorem 1.2, the computer would need to solve a system of non-linear equations (eg. see example 2), which is a very difficult task for the computer. \\\\
	\textbf{ACTL3182 use:} (Will make sense after the lecture) We want to minimise the portfolio variance \( \sigma_P^2 = \bm{w}^{\top}\Sigma \bm{w} \) with respect to the constraints \( \bm{1}^{\top}\bm{w} = 1 \) and \( \bm{z}^{\top}\bm{w} = \mu \). The Lagrangian is given by
	\begin{align*}
		\mathcal{L}(\bm{w}, \lambda, \gamma)  = \frac{1}{2} \bm{w}^{\top} \Sigma \bm{w} + \lambda (1 - \bm{1}^{\top}\bm{w}) + \gamma (\mu - \bm{z}^{\top}\bm{w}),
	\end{align*}
	and the required conditions are 
	\begin{align*}
		\frac{\partial \mathcal{L}}{\partial\bm{w}} = \Sigma\bm{w} - \lambda\bm{1} - \gamma \bm{z} = \bm{0}, \qquad \frac{\partial \mathcal{L}}{\partial\lambda} = 1 - \bm{1}^{\top}\bm{w} = 0, \qquad\text{and}\quad \frac{\partial \mathcal{L}}{\partial\gamma} = \mu - \bm{z}^{\top}\bm{w} = 0.
	\end{align*}
	\newpage
 	\section{Appendix}
 	\begin{example}{Two constraints}{}
 		Find the point(s) where the function \( f(x,y,z) = xyz \) attains its maximum value on the unit sphere \( x^2+y^2+z^2 = 1 \) and the plane \( x - y + z = 1 \).
 	\end{example}
 	\noindent \textbf{Solution:} Define the functions \( g_1, g_2:\R^3 \to\R \), where
 	\begin{align*}
 	& g_1(x,y,z) = x^2 + y^2 + z^2 \\
 	& g_2(x,y,z) = x - y + z.
 	\end{align*}
 	We want to maximise the function \( f \) with respect to the constraints \( g_1(x,y,z) = 1 \) and \( g_2(x,y,z) = 1 \). By the method of Lagrange multipliers, 
 	\begin{align*}
 	& \nabla f = \lambda \nabla g_1 + \gamma \nabla g_2 \\
 	\iff & (yz, xz, xy)^{\top} = \lambda (2x, 2y, 2z)^{\top} + \gamma(1, -1, 1)^{\top} 
 	\end{align*}
 	yielding the three equations:
 	\begin{align}
 	& yz = 2\lambda x + \gamma \\ 
 	& xz = 2\lambda y - \gamma \\
 	& xy = 2\lambda z + \gamma.
 	\end{align}
 	We eliminate \( \gamma \) by finding \( (1) + (2) \) and \( (1) + (3) \):
 	\begin{align}
 	& z(x + y)  = 2\lambda(x + y) \iff (z - 2\lambda)(x + y) =0 \\
 	& x(y+z) = 2\lambda (y + z) \iff (x - 2\lambda) (y + z) = 0
 	\end{align}
 	\textbf{Case 1:} If \( x \neq - y \) and \( y\neq -z \), then (4) and (5) reduce to 
 	\begin{align*}
 	x = 2\lambda = z.
 	\end{align*}
 	Substituting into \( g_2(x,y,z) = 1 \), we obtain \( y = 2x - 1 \). Substituting into \( g_1(x,y,z) = 1 \), we obtain 
 	\begin{align*}
 	& 2x^2 + (2x -1)^2 = 1 \\
 	\iff & x(3x - 2) = 0.
 	\end{align*}
 	If \( x = 0 \), then \( f = 0 \) and if \( x = 2/3 \), then \( y = 1/3, z = 2/3 \) and \( f = 4/27 >0 \). Thus, the maximum value of \( f \) given the constraints is \( 4/27 \). \\\\
 	\textbf{Case 2:} If \( x \neq -y \) but \( y = -z \), then, \( z = 2\lambda \) and \( y = -2\lambda \). Substituting into \( g_2(x,y,z) = 1 \), we obtain \( x = 1 - 4\lambda \). Substituting into \( g_{1}(x,y,z) = 1 \), we obtain \( \lambda = 0, 1/3 \). Ignoring \( \lambda = 0 \) (this gives another minimum) and taking \( \lambda = 1/3 \), we obtain \( x = -1/3, y = -2/3, z = 2/3 \).\\\\
 	\textbf{Case 3:} If \( x = -y \) but \( y\neq - z \), then \( x = 2\lambda \), and similarly to case 2, we obtain \( x = 2/3, y = -2/3, z = -1/3 \). \\\\
 	\textbf{Case 4:} If \( x = -y \) and \( y = -z \), then substituting into \( g_{2}(x,y,z)  =1 \), we obtain \( y = -1/3 \), while substituting into \( g_{1}(x,y,z) = 1 \) yields \( y = \pm 1/\sqrt{3} \). Hence, these conditions and the constraints are incompatible, so no maxima occur in this case.\\\\
 	Thus, \( f \) is maximised with repsect to the constraint \( g_1(x,y,z) = 1 \) and \( g_{2}(x,y,z) = 1 \) at the points 
 	\[	\left(\frac{2}{3}, \frac{1}{3}, \frac{2}{3}\right),\qquad \left(-\frac{1}{3}, -\frac{2}{3}, \frac{2}{3}\right), \qquad\text{and}\quad\left(\frac{2}{3}, -\frac{2}{3}, \frac{1}{3}\right).
 	\]
 	
 	\noindent Here are two exercises in case you want to practice applying Lagrange multipliers. Again, the questions in ACTL3182 are \textbf{not} like these exercises, but they may be helpful for your understanding. Worked solutions for these exercises will not be given.\\ 
 	\begin{exercise}
 		\begin{enumerate}
 			\item *Find the maximum and minimum values of \( f(x,y) = x^2 + x + 2y^2 \) on the unit circle \( x^2 + y^2 = 1 \).
 			\item \textbf{MATH1251 2012 Final 3iv):} Find the points on the ellipse \( 2x^2 - 4xy + 5y^2 = 54 \) that are closest to the origin. \\[3pt]Hint: Find two expressions for \( \frac{y}{x} \) in terms of \( \lambda \), then find the value(s) of \( \lambda \).
 		\end{enumerate}
 		\tcblower
 		Answers: 1. Minimum value is 0, maximum value is \( 9/4 \) \hspace{1cm} 2. \( \left(\frac{-3}{\sqrt{5}}, \frac{6}{\sqrt{5}}\right) \) and \(\left(\frac{3}{\sqrt{5}}, -\frac{6}{\sqrt{5}}\right)   \)
  	\end{exercise}
  	\bigskip
  	\noindent *Problem taken from James McKernan. \textit{18.022 Calculus of Several Variables}. Fall 2010. Massachusetts Institute of Technology: MIT OpenCourseWare, \href{https://ocw.mit.edu/courses/mathematics/18-022-calculus-of-several-variables-fall-2010}{https://ocw.mit.edu}, License: \href{https://creativecommons.org/licenses/by-nc-sa/4.0/}{Creative Commons BY-NC-SA.}
  	
  	%Add INTUITION OF LAGRANGE MULTIPLIERS USING CONTOURS IF TIME.
	\end{document}